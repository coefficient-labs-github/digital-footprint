name: Digital Footprint Analysis

on:
  workflow_dispatch:
    inputs:
      person_name:
        description: 'Name of the person to analyze'
        required: true
        type: string

jobs:
  analyze:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Create data directory
      run: mkdir -p data/transcripts
        
    - name: Scrape YouTube content
      id: youtube
      env:
        PERSON_NAME: ${{ github.event.inputs.person_name }}
        APIFY_API_KEY: ${{ secrets.APIFY_API_KEY }}
      run: |
        python -c "
        from src.scrapers.youtube import YouTubeScraper
        from src.data.storage import DataStorage
        storage = DataStorage()
        scraper = YouTubeScraper()
        links = scraper.search_podcasts('$PERSON_NAME')
        storage.save_links('youtube', links)
        "
        
    - name: Scrape LinkedIn content
      id: linkedin
      env:
        PERSON_NAME: ${{ github.event.inputs.person_name }}
        APIFY_API_KEY: ${{ secrets.APIFY_API_KEY }}
      run: |
        python -c "
        from src.scrapers.linkedin import LinkedInScraper
        from src.data.storage import DataStorage
        storage = DataStorage()
        scraper = LinkedInScraper()
        links = scraper.search_posts('$PERSON_NAME')
        storage.save_links('linkedin', links)
        "
        
    - name: Scrape Twitter content
      id: twitter
      env:
        PERSON_NAME: ${{ github.event.inputs.person_name }}
        APIFY_API_KEY: ${{ secrets.APIFY_API_KEY }}
      run: |
        python -c "
        from src.scrapers.twitter import TwitterScraper
        from src.data.storage import DataStorage
        storage = DataStorage()
        scraper = TwitterScraper()
        links = scraper.search_posts('$PERSON_NAME')
        storage.save_links('twitter', links)
        "
        
    - name: Process YouTube transcripts
      id: transcripts
      env:
        PERSON_NAME: ${{ github.event.inputs.person_name }}
      run: |
        python -c "
        from src.processors.transcript import TranscriptProcessor
        from src.data.storage import DataStorage
        storage = DataStorage()
        processor = TranscriptProcessor()
        youtube_links = storage.load_links('youtube')
        for video_id in youtube_links:
            if not storage.load_transcript(video_id):
                transcript = processor.get_transcript(video_id)
                storage.save_transcript(video_id, transcript)
        "
        
    - name: Upload results
      uses: actions/upload-artifact@v3
      with:
        name: analysis-results
        path: data/ 